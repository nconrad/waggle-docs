<!doctype html>
<html lang="en" dir="ltr" class="mdx-wrapper mdx-page plugin-pages plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Social Distancing | Sage Website</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://nconrad.github.io/waggle-docs/science/social-distancing"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Social Distancing | Sage Website"><meta data-rh="true" name="description" content="My name is Ori Zur and I am a rising junior at Northwestern University studying computer science and music composition. This summer at Argonne, I sought to answer the following question: how well are people following social distancing guidelines in outdoor urban environments?"><meta data-rh="true" property="og:description" content="My name is Ori Zur and I am a rising junior at Northwestern University studying computer science and music composition. This summer at Argonne, I sought to answer the following question: how well are people following social distancing guidelines in outdoor urban environments?"><link data-rh="true" rel="icon" href="/waggle-docs/img/sage-favicon.png"><link data-rh="true" rel="canonical" href="https://nconrad.github.io/waggle-docs/science/social-distancing"><link data-rh="true" rel="alternate" href="https://nconrad.github.io/waggle-docs/science/social-distancing" hreflang="en"><link data-rh="true" rel="alternate" href="https://nconrad.github.io/waggle-docs/science/social-distancing" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://MPDJQF6T11-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/waggle-docs/blog/rss.xml" title="Sage Website RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/waggle-docs/blog/atom.xml" title="Sage Website Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Sage Website" href="/waggle-docs/opensearch.xml"><link rel="stylesheet" href="/waggle-docs/assets/css/styles.ec7e0d24.css">
<link rel="preload" href="/waggle-docs/assets/js/runtime~main.5b3cb2e1.js" as="script">
<link rel="preload" href="/waggle-docs/assets/js/main.09bb6aac.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/waggle-docs/"><div class="navbar__logo"><img src="/waggle-docs/img/logo.png" alt="Site Logo" class="themedImage_ToTc themedImage--light_HNdA custom-navbar-logo-class"><img src="/waggle-docs/img/logo_dark.svg" alt="Site Logo" class="themedImage_ToTc themedImage--dark_i4oU custom-navbar-logo-class"></div><b class="navbar__title text--truncate">Sage</b></a><a class="navbar__item navbar__link" href="/waggle-docs/about">About</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/waggle-docs/science">Science</a><a class="navbar__item navbar__link" href="/waggle-docs/blog">News</a><a class="navbar__item navbar__link" href="/waggle-docs/publications">Publications</a><a class="navbar__item navbar__link" href="/waggle-docs/team">Team</a><a class="navbar__item navbar__link" href="/waggle-docs/docs/about/overview">Docs</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link header-github-link" aria-label="GitHub repository"></a><ul class="dropdown__menu"><li><a href="https://github.com/sagecontinuum" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sage GitHub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/waggle-sensor" target="_blank" rel="noopener noreferrer" class="dropdown__link">Waggle Sensor GitHub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="SignInBtn__Root-sc-1lj79ef-0 fqsrYB"><style data-emotion="css 6ii3fu">.css-6ii3fu{font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:0.875rem;line-height:1.75;letter-spacing:0.02857em;text-transform:uppercase;min-width:64px;padding:5px 15px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;border:1px solid rgba(25, 118, 210, 0.5);color:#1976d2;}.css-6ii3fu:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(25, 118, 210, 0.04);border:1px solid #1976d2;}@media (hover: none){.css-6ii3fu:hover{background-color:transparent;}}.css-6ii3fu.Mui-disabled{color:rgba(0, 0, 0, 0.26);border:1px solid rgba(0, 0, 0, 0.12);}</style><style data-emotion="css 79xub">.css-79xub{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:0.875rem;line-height:1.75;letter-spacing:0.02857em;text-transform:uppercase;min-width:64px;padding:5px 15px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;border:1px solid rgba(25, 118, 210, 0.5);color:#1976d2;}.css-79xub::-moz-focus-inner{border-style:none;}.css-79xub.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-79xub{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-79xub:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(25, 118, 210, 0.04);border:1px solid #1976d2;}@media (hover: none){.css-79xub:hover{background-color:transparent;}}.css-79xub.Mui-disabled{color:rgba(0, 0, 0, 0.26);border:1px solid rgba(0, 0, 0, 0.12);}</style><a class="MuiButtonBase-root MuiButton-root MuiButton-outlined MuiButton-outlinedPrimary MuiButton-sizeMedium MuiButton-outlinedSizeMedium MuiButton-root MuiButton-outlined MuiButton-outlinedPrimary MuiButton-sizeMedium MuiButton-outlinedSizeMedium css-79xub" tabindex="0" href="https://portal.sagecontinuum.org">Portal<style data-emotion="css 1n4a93h">.css-1n4a93h{display:inherit;margin-right:-4px;margin-left:8px;}.css-1n4a93h>*:nth-of-type(1){font-size:20px;}</style><span class="MuiButton-endIcon MuiButton-iconSizeMedium css-1n4a93h"><style data-emotion="css vubbuv">.css-vubbuv{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;}</style><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="LoginRoundedIcon"><path d="M10.3 7.7c-.39.39-.39 1.01 0 1.4l1.9 1.9H3c-.55 0-1 .45-1 1s.45 1 1 1h9.2l-1.9 1.9c-.39.39-.39 1.01 0 1.4.39.39 1.01.39 1.4 0l3.59-3.59c.39-.39.39-1.02 0-1.41L11.7 7.7a.9839.9839 0 0 0-1.4 0zM20 19h-7c-.55 0-1 .45-1 1s.45 1 1 1h7c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2h-7c-.55 0-1 .45-1 1s.45 1 1 1h7v14z"></path></svg></span></a></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><main class="container container--fluid margin-vert--lg"><div class="row mdxPageWrapper_j9I6"><div class="col col--8"><article><h1>Social Distancing</h1><p>My name is Ori Zur and I am a rising junior at Northwestern University studying computer science and music composition. This summer at Argonne, I sought to answer the following question: how well are people following social distancing guidelines in outdoor urban environments?</p><p>For the past six months, the world has been enduring a historic pandemic due to the COVID-19 virus. As society attempts to adjust to the new lifestyle of mask wearing, virtual education, and working from home, one phrase that constantly gets brought up is “social distancing guidelines.” Social distancing is the action of keeping a distance of at least six feet from others in order to reduce the spread of the Coronavirus disease. For the past two months, I’ve been designing and coding a social distancing detector using Python and OpenCV as a means to answer the question of what percentage of people are properly following these social distancing guidelines.</p><p>The program takes a video of pedestrians, typically from surveillance camera footage, and analyzes each frame by detecting the people, calculating the distance between each pair of people, and indicating if any two people are standing less than six feet apart. OpenCV, a computer vision function library, was used because it greatly simplifies the process of loading in a video, separating it into individual frames for analysis and editing, and outputting the final results.</p><p><img loading="lazy" alt="original image" src="/waggle-docs/assets/images/social-distancing-1-e09bcb65c31d9faa5e8bb6858e7ea0d0.png" width="1490" height="834" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-it-works">How it works<a href="#how-it-works" class="hash-link" aria-label="Direct link to How it works" title="Direct link to How it works">​</a></h2><p>There are two main components to the program: the setup, which only occurs once in the beginning, and the operation, which is a loop that occurs once for each frame of the input video.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-setup">The setup<a href="#the-setup" class="hash-link" aria-label="Direct link to The setup" title="Direct link to The setup">​</a></h2><p>When the program begins running, the first frame of the input video is shown to the user. The user then inputs six points with their mouse. The first four points make up a rectangle on the ground plane, which will be referred to as the “region of interest” or ROI. The last two points are an approximation of a six-foot distance on the ground.</p><p><img loading="lazy" alt="original image" src="/waggle-docs/assets/images/social-distancing-2-86bec21de75829c18c7ab2a30569f990.png" width="2048" height="1264" class="img_ev3q"></p><p>Six mouse points inputed by the user on the first frame of the input video. The four blue points make up the region of interest and the two green points are the six-foot approximation. Here, the height of the person was used to approximate six feet, but ideally there would be markers on the ground to help guide the user in plotting these points.
The purpose of creating a region of interest with the first four mouse points is to solve the issue of camera distortion. Because the camera is filming from an angle, the conversion rate between physical distance on the ground and pixel distance in the image is not constant. In order to solve this problem, the four mouse points are used to warp the region of interest to create a bird’s-eye-view image. This new image, shown below, looks distorted and unclear, but its appearance is irrelevant as it won’t be shown to the user. What’s important is that in the warped image, the conversion rate between physical distance and pixel distance is now constant.</p><p><img loading="lazy" alt="original image" src="/waggle-docs/assets/images/social-distancing-3-f6de48e4ac2ce4a0553701ac88445ae1.png" width="750" height="570" class="img_ev3q"></p><blockquote><p>Original Image</p></blockquote><p><img loading="lazy" alt="warped view of image" src="/waggle-docs/assets/images/social-distancing-4-f8851d5722d1462cb7fb19c42df579ab.png" width="267" height="518" class="img_ev3q"></p><blockquote><p>Warped Bird’s Eye View Image</p></blockquote><p>In order to prove that this works, I created a small-scale experiment using LEGOs and ran the image through the same warping function. On the left, the tick marks on the sides of the paper are not evenly spaced in terms of pixel distance due to the camera angle. On the right image, however, the tick marks on the side of the paper are evenly spaced, indicating that the physical distance to pixel distance conversion rate is now constant.</p><p><img loading="lazy" alt="original vs transformation" src="/waggle-docs/assets/images/social-distancing-5-b8654fab330ac55f043e7b27b5c19002.png" width="1316" height="568" class="img_ev3q"></p><blockquote><p>Left: original image, four blue points are inputed by the user via mouse clicks. Right: result of image transformation.</p></blockquote><p>The last part of setup is to use the last two inputted mouse points to calculate the number of pixels that make up six feet. The coordinates of these two points are warped using the same function used to warp the image, and the distance formula is used to calculate the number of pixels between them. This distance is the number of pixels that make up six feet, which I call the minimum safe distance, and since the points and image were warped using the same function, this pixel distance is the same throughout the entire bird’s-eye-view image.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-operation">The operation<a href="#the-operation" class="hash-link" aria-label="Direct link to The operation" title="Direct link to The operation">​</a></h2><p>The first step of the operation loop is person detection, which is accomplished using a real-time object detection program called You Only Look Once, or YOLO. This program recognizes a wide variety of objects, but my program includes a filter that only keeps the person recognitions. Once detection occurs, each person is represented by what’s called a “bounding box,” which is a rectangle whose coordinates surround the person.</p><p>The next step is to take a single point from each bounding box, warp it using the same function used in the setup, and map the coordinates of the warped box points onto the bird’s-eye-view image. Because everything is now mapped onto the bird’s-eye-view image, the distance formula can be used to calculate the distances between each pair of points. These distances are then compared to the minimum safe distance which was also calculated in the setup.</p><p>The final step is to create and display the outputs for the current frame. The first output is the street view, where red and green rectangles are drawn on the bounding boxes of the detected people. The second output is a representation of the bird’s-eye-view image using a white window and green and red circles to represent the warped box coordinates that were mapped in the previous step. Once the outputs are displayed, the loop moves onto the next frame of the input video.</p><p><img loading="lazy" alt="screenshot of program" src="/waggle-docs/assets/images/social-distancing-6-e2180ce9472a8fb62764b89c16c0587e.png" width="2048" height="1011" class="img_ev3q"></p><blockquote><p>Screenshot of the program in action.  Left: bird’s-eye-view output.  Right: street view output</p></blockquote><p>Here is a flowchart that summarizes the steps of the setup and operation components of the program.</p><p><img loading="lazy" alt="steps of algorithm" src="/waggle-docs/assets/images/social-distancing-7-ac9c3ce8e28971f85b22ccd478e9bd1e.png" width="1318" height="630" class="img_ev3q"></p><blockquote><p>Setup steps are in orange and operation steps are in green.</p></blockquote><h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next steps" title="Direct link to Next steps">​</a></h2><p>One feature that I plan to add to the program in my remaining time at Argonne is the ability to detect groups of people walking together. For example, a couple or family walking together may be less than six feet apart, but that should not be considered a violation of social distancing guidelines. This will be done by adding in an algorithm that can associate objects across multiple frames and assign unique IDs to each person detected. Using this algorithm, my program will be able to recognize groups of people walking together by tracking their specific object IDs, and disregard them as violators even if they are standing too close together.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h2><ol><li><a href="https://github.com/deepak112/Social-Distancing-AI" target="_blank" rel="noopener noreferrer">https://github.com/deepak112/Social-Distancing-AI</a></li><li><a href="https://github.com/aqeelanwar/SocialDistancingAI" target="_blank" rel="noopener noreferrer">https://github.com/aqeelanwar/SocialDistancingAI</a></li><li><a href="https://www.pyimagesearch.com/2020/06/01/opencv-social-distancing-detector/" target="_blank" rel="noopener noreferrer">https://www.pyimagesearch.com/2020/06/01/opencv-social-distancing-detector/</a></li><li><a href="https://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/" target="_blank" rel="noopener noreferrer">https://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/</a></li><li><a href="https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/" target="_blank" rel="noopener noreferrer">https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/</a></li></ol></article></div><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#how-it-works" class="table-of-contents__link toc-highlight">How it works</a></li><li><a href="#the-setup" class="table-of-contents__link toc-highlight">The setup</a></li><li><a href="#the-operation" class="table-of-contents__link toc-highlight">The operation</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next steps</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></main></div><footer class="footer"><div class="container container-fluid"></div></footer></div>
<script src="/waggle-docs/assets/js/runtime~main.5b3cb2e1.js"></script>
<script src="/waggle-docs/assets/js/main.09bb6aac.js"></script>
</body>
</html>